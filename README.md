# MedViT-CAMIL

**Context-Aware Multiple Instance Learning for Medical Video Analysis**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ ProblÃ¨me de Recherche

DÃ©tection d'**anomalies rares** dans des sÃ©quences mÃ©dicales (vidÃ©os/volumes 3D) sur des appareils Ã  ressources limitÃ©es.

**DÃ©fi principal** : L'anomalie n'apparaÃ®t que sur quelques frames (ex: 5/200), ce qui pose le problÃ¨me de "l'aiguille dans la botte de foin". Les mÃ©thodes classiques (average pooling) diluent le signal par un facteur de ~40x.

## ğŸ§¬ Architecture ProposÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MedViT-CAMIL                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   VidÃ©o (T, 3, H, W)                                        â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚  MobileViT (â„ï¸)  â”‚  â† Backbone gelÃ©, prÃ©-entraÃ®nÃ©       â”‚
â”‚   â”‚  Feature Extractorâ”‚                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚ Features (T, D)                                â”‚
â”‚            â–¼                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚   Conv1D (k=3)  â”‚  â† Contexte local [t-1, t, t+1]      â”‚
â”‚   â”‚   Temporal      â”‚                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚ Gated Attention â”‚  â† V: Tanh (contenu)                 â”‚
â”‚   â”‚      MIL        â”‚  â† U: Sigmoid (gate)                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚ Aggregated (D,)                                â”‚
â”‚            â–¼                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚   Classifier    â”‚  â†’ Logits (num_classes)              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Contribution Scientifique

Le module **CAMIL** (Context-Aware Multiple Instance Learning) combine :

1. **Conv1D temporelle** : VÃ©rifie la cohÃ©rence locale sur 3 frames consÃ©cutives
2. **Gated Attention** (Ilse et al., ICML 2018) : Le gate sigmoid peut "fermer" l'attention sur les frames bruitÃ©es, contrairement au softmax standard qui distribue toujours de l'attention

## ğŸ“ Structure du Projet

```
MedViT_Research/
â”œâ”€â”€ Dockerfile              # Image Docker pour dÃ©ploiement
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ run.sh                  # Script de lancement (Linux/Mac)
â”œâ”€â”€ run.bat                 # Script de lancement (Windows)
â”œâ”€â”€ README.md               # Ce fichier
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Configuration (modes TEST/REAL)
â”‚   â”œâ”€â”€ dataset.py          # Datasets synthÃ©tiques + MedMNIST
â”‚   â”œâ”€â”€ model.py            # Architectures Baseline et CAMIL
â”‚   â””â”€â”€ main.py             # EntraÃ®nement et Ã©valuation
â”œâ”€â”€ data/                   # DonnÃ©es (auto-tÃ©lÃ©chargÃ©es)
â””â”€â”€ results/                # RÃ©sultats et visualisations
```

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8+
- PyTorch 2.0+
- CUDA (optionnel, pour GPU)

### Installation des dÃ©pendances

```bash
cd MedViT_Research
pip install -r requirements.txt
```

## ğŸ’» Utilisation

### Mode TEST (Validation locale rapide)

Utilise des **donnÃ©es synthÃ©tiques** avec bruit speckle simulÃ© :

```bash
# Windows
run.bat test

# Linux/Mac
./run.sh test

# Ou directement
python src/main.py --mode test
```

**ParamÃ¨tres TEST** : 16 frames, 3 Ã©poques, batch=4, ~100 samples

### Mode REAL (Production)

Utilise **NoduleMNIST3D** (nodules pulmonaires CT) :

```bash
# Windows
run.bat real

# Linux/Mac
./run.sh real

# Ou directement
python src/main.py --mode real
```

**ParamÃ¨tres REAL** : 28 slices, 15 Ã©poques, batch=8, ~1600 samples

### Options supplÃ©mentaires

```bash
# Dry-run (vÃ©rifie la config sans entraÃ®ner)
python src/main.py --mode test --dry-run

# Custom epochs
python src/main.py --mode test --epochs 10

# Custom batch size
python src/main.py --mode real --batch-size 4

# Custom learning rate
python src/main.py --mode test --lr 0.0001
```

## ğŸ“Š RÃ©sultats Attendus

| ModÃ¨le | Mode | Accuracy Attendue |
|--------|------|-------------------|
| Baseline (Avg Pool) | TEST | ~50-60% |
| MedViT-CAMIL | TEST | ~70-85% |
| Baseline (Avg Pool) | REAL | ~60-70% |
| MedViT-CAMIL | REAL | ~80-90% |

### Visualisations gÃ©nÃ©rÃ©es

- `training_curves_*.png` : Courbes loss/accuracy comparatives
- `attention_heatmap_*.png` : Heatmaps d'attention temporelle
- `attention_comparison_*.png` : Comparaison Baseline vs CAMIL
- `results_*.json` : MÃ©triques dÃ©taillÃ©es

## ğŸ”¬ Dataset: NoduleMNIST3D

[NoduleMNIST3D](https://medmnist.com/) fait partie de MedMNIST v2 (Nature Scientific Data 2023).

| CaractÃ©ristique | Valeur |
|-----------------|--------|
| ModalitÃ© | Chest CT |
| TÃ¢che | Classification binaire (malin/bÃ©nin) |
| Dimensions | 28Ã—28Ã—28 |
| Train/Val/Test | 1,158 / 165 / 310 |
| TÃ©lÃ©chargement | Automatique (~50 Mo) |

> **Note** : NoduleMNIST3D est un volume 3D spatial, pas une vidÃ©o temporelle. Cependant, mathÃ©matiquement le tenseur $(D, H, W)$ se traite identiquement Ã  $(T, H, W)$, ce qui est acceptable pour le PoC.

## ğŸ³ Docker (Optionnel)

```bash
# Build
docker build -t medvit-camil .

# Run mode test
docker run --gpus all -v $(pwd)/results:/app/results medvit-camil test

# Run mode real
docker run --gpus all -v $(pwd)/results:/app/results medvit-camil real
```

## ğŸ“š RÃ©fÃ©rences

- **MobileViT** : Mehta & Rastegari, "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer", ICLR 2022
- **Gated Attention MIL** : Ilse et al., "Attention-based Deep Multiple Instance Learning", ICML 2018
- **MedMNIST** : Yang et al., "MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification", Nature Scientific Data 2023

## ğŸ“ Licence

MIT License - Voir [LICENSE](LICENSE)

## ğŸ‘¥ Auteurs

Projet de recherche M2 - ENSPY (Ã‰cole Nationale SupÃ©rieure Polytechnique de YaoundÃ©)

*"Design of Next-Generation Generative and Agentic AI Architectures for Complex, Long-Horizon, and Multimodal Intelligence Tasks"*
